{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanvirniaz/Documents/Python/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,LSTM,Dense\n",
    "from keras.optimizers import Adam\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing song data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to obtain list of song names\n",
    "def getlyriclist (txt):\n",
    "    lyricstring = open(txt).read() #opens .txt file with lyrics scrape from Genius\n",
    "    lyricstring2 = re.sub('[^a-zA-Z0-9Z*\\n\\.]', ' ', lyricstring) #cleans text data\n",
    "    lyriclist=lyricstring2.split('**') #splits into list with placeholder marker **\n",
    "    return (lyriclist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyriclist= getlyriclist('alllyrics.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to obtain all lyrics text from song names\n",
    "def getalltxt(lyriclist):\n",
    "    alltxt='' \n",
    "    for i in range (len(lyriclist)):\n",
    "        alltxt+=lyriclist[i] #saves all lyrics combined into one string alltxt\n",
    "    return (alltxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltxt=getalltxt(lyriclist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transformation for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to obtain dictionary comprehensions and vocab size from alltxt\n",
    "def vocabdict(alltxt):\n",
    "    vocab=list(set(alltxt)) #list of all unqiue characters in txt- list comprehension\n",
    "    char_ix={c:i for i,c in enumerate(vocab)} #dictionary for vocab- dictionary comprehension\n",
    "    ix_char={i:c for i,c in enumerate(vocab)} #dictionary for vocab- dictionary comprehension\n",
    "    vocabsize=len(vocab) #total length of vocab set\n",
    "    return char_ix,ix_char,vocabsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_ix,ix_char,vocabsize=vocabdict(alltxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformalltxt(alltxt,maxlen):\n",
    "    sentences=[] #placeholder for sentences\n",
    "    nextchar=[] #placeholder for next character\n",
    "    for i in range(len(alltxt)-maxlen-1): #iterate through alltxt\n",
    "        sentences.append(alltxt[i:i+maxlen]) #list of all sentences\n",
    "        nextchar.append(alltxt[i+maxlen]) #list of all next characters\n",
    "    return sentences,nextchar, maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, nextchar, maxlen= transformalltxt(alltxt,40) #using maxlen 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing x,y arrays for modelling\n",
    "def getxy (sentences,maxlen,vocabsize,char_ix):\n",
    "    #array of sentences x will predict array of nextchar y\n",
    "    x=np.zeros((len(sentences),maxlen,vocabsize)) #x is array of 3D shape for sentences: (samples, timesteps, features)\n",
    "    y=np.zeros((len(sentences),vocabsize)) #y is array of 2D shape for nextchar: (samples,features)\n",
    "    #populating x,y arrays using dictionary for vocab\n",
    "    for ix in range(len(sentences)): #iterate over range of total samples\n",
    "        y[ix,char_ix[nextchar[ix]]]=1 #y array index over all samples becomes true  for feature present (nextchar)\n",
    "        for iy in range(maxlen): #iterate over range of samples timesteps\n",
    "            x[ix,iy,char_ix[sentences[ix][iy]]]=1 #x array index for all samples,timesteps becomes true for feature present (sentence timestep)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=getxy(sentences,maxlen,vocabsize,char_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10)                3040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 65)                715       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 65)                0         \n",
      "=================================================================\n",
      "Total params: 3,755\n",
      "Trainable params: 3,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#modelling using LSTM model\n",
    "model=Sequential()\n",
    "model.add(LSTM(10,input_shape=(maxlen,vocabsize))) #hidden state: 10, timesteps: 40 (maxlen), features: len(vocabsize)\n",
    "model.add(Dense(vocabsize)) #add regular densely connected NN layers (len(vocab))\n",
    "model.add(Activation('softmax')) #final softmax activation layer\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=0.01),loss='categorical_crossentropy') #configure model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "826574/826574 [==============================] - 233s 282us/step - loss: 2.2844\n",
      "Epoch 2/5\n",
      "826574/826574 [==============================] - 233s 281us/step - loss: 2.0739\n",
      "Epoch 3/5\n",
      "826574/826574 [==============================] - 224s 271us/step - loss: 2.0360\n",
      "Epoch 4/5\n",
      "826574/826574 [==============================] - 224s 271us/step - loss: 2.0172\n",
      "Epoch 5/5\n",
      "826574/826574 [==============================] - 223s 270us/step - loss: 2.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb1f1bae80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=5,batch_size=256) #fitting model to x,y data with batch size 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate predictions\n",
    "def generate(alltxt,maxlen):\n",
    "#setting a random starting index and sentence for predicting\n",
    "    generated ='' #intializing generated string\n",
    "    start_index=random.randint(0,len(alltxt)-maxlen-1) #random start index between 0 and last next char value over len(txt)\n",
    "    sent=alltxt[start_index:start_index+maxlen] #sentence from random start index\n",
    "    generated+=sent #adds sentence values to generated string (first 40 characters)\n",
    "#converting generated string to array of corresponding vocab dictionary values\n",
    "    for i in range(1900): #for range of arbitrary song lyrics length (1900 characters)\n",
    "        x_sample=generated[i:i+maxlen] #save generated characters to array x_sample\n",
    "        samp=np.zeros((1,maxlen,vocabsize)) #initialize samp array of 1 sample, maxlen timesteps, vocabsize features\n",
    "        for j in range(maxlen): #iterate over samp timesteps\n",
    "            samp[0,j,char_ix[x_sample[j]]]=1 #converting string x_sample to samp index array; values over timesteps are true for feature (character)\n",
    "        probs=model.predict(samp) #based on samp array input, predicts probabilities of next character\n",
    "        probs=np.reshape(probs,probs.shape[1]) #reshape prediction to one column\n",
    "        ix=np.random.choice(range(vocabsize),p=probs.ravel()) #returns a random character index (vocab index) from 1-D array of probabilities from model\n",
    "        generated+=ix_char[ix] #convert the character index into a character and add it to generated string\n",
    "    print (generated) #return the egnerated string of 1940 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nd nBaby I like your style nYa unruly mue got for minkn nFill nCabha din  sthan that  fiad sous  bicky I ond nAnd gleso that t to   they nSeart tryne sorut eistal nep. I s mids in nYaarle nafne solje is me yeahoyll am wiwi nawy t*yull and wichect nJlisiriet thip hing got t not theza crinky  frens  nRspise cee the  rounst you wan us nLer nCauk n tkivi      Wasyfy nHoom you and n fhan    shoro that thee t up the side fwatky asery it shet nOr funs then sone anteld bat no cow bigg you  Kyisty  I avery wes yurt I bussing bah out domy bongh nAnd  sthatan t ay me nCabl acts inee dol.  Liky    t on frensy jom jugct staytin   I rad coud to nera get matteme I treef notring lam suls  1 on nAnd hit chilld werece nGot s mathid wein the con trem wows  ple ay taittotelly donly but bestrin  I is mast cist that ureh not wilp says it was flot  chockely   mer to s andyoytan of trerint gomn a re conding  but body fup lout yitin    that ut   you nen ading stins wing but  how Masts a he firl shet gong  s sorkading bally sthe utres uts aney me it way even  metane that nFoldin  nSeest to gayt nYea nC hespin  I abouw nI d afy maks bouph  Prelorie that ley  amidlich n Cherousyt foach kto sousin a anming re watk I bal ceef enge thoten  Show Leemuse an    Qus ther cruny so  nBhad cleed woos hwram it lalondy mey hannn  then as wane  uh nThoockte I nLaico doniat love and that  ake men that lut I ouse na botissend   measey gets the get cold c nBut nI we cold  next sttin exstellin   sos nWahay like hich nYin  nYout you rididne  but my sane knle birle torale  Hoot nat when ever soud nAnd knotresedle  Ass monend from my you  nNerras nI res to wowe tfeim nYerogahh sheh con whan Bou nSken could nI I gim you tapk  the cop  in taad link you read worin t nIt you fout how  nI t like mase neots sbiisto lunt bener  nFuve s jutt yerith drelriensshy to coulad wan a uh nI resty ane  n tuall myming souse tameing athaky the how sematy iym. Stcthight ges\n"
     ]
    }
   ],
   "source": [
    "generate(alltxt,maxlen) #first generated lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
